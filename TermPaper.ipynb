{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe1c3bd",
   "metadata": {},
   "source": [
    "Our student exam numbers given for this exam \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b312d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505216fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importCSV():\n",
    "    months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    all_dfs = []\n",
    "\n",
    "    for month in months:\n",
    "        for year in range(2014, 2025):\n",
    "            csv_string = f\"Term paper/data/SCE-{month}-{year}.csv\" \n",
    "            try:\n",
    "                csv_file = pd.read_csv(csv_string, sep=\";\")\n",
    "                all_dfs.append(csv_file)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Filen {csv_string} finnes ikke.\")\n",
    "\n",
    "    return  pd.concat(all_dfs)\n",
    "df = importCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0a9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique persons: 21666\n",
      "number of rows: 165924\n",
      "Number of unique survey waves: 132\n",
      "earliest_date: 2014-01-02\n",
      "latest date: 2024-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70016297</td>\n",
       "      <td>201401</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70016329</td>\n",
       "      <td>201401</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70016366</td>\n",
       "      <td>201401</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70016375</td>\n",
       "      <td>201401</td>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70016445</td>\n",
       "      <td>201401</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid     wid        date  weight  female  educ   age  hispanic  black  \\\n",
       "0  70016297  201401  2014-01-07     1.0     0.0   4.0  29.0       0.0    0.0   \n",
       "1  70016329  201401  2014-01-02     4.5     1.0   2.0  43.0       0.0    0.0   \n",
       "2  70016366  201401  2014-01-07     0.6     0.0   4.0  30.0       0.0    0.0   \n",
       "3  70016375  201401  2014-01-16     0.7     1.0   4.0  28.0       0.0    0.0   \n",
       "4  70016445  201401  2014-01-19     0.5     0.0   4.0  47.0       1.0    0.0   \n",
       "\n",
       "   couple  ...  num_lit_q3  num_lit_q3_correct  num_lit_q5  \\\n",
       "0     NaN  ...         NaN                 NaN         NaN   \n",
       "1     NaN  ...         NaN                 NaN         NaN   \n",
       "2     NaN  ...         NaN                 NaN         NaN   \n",
       "3     NaN  ...         NaN                 NaN         NaN   \n",
       "4     NaN  ...         NaN                 NaN         NaN   \n",
       "\n",
       "   num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                 NaN         NaN                 NaN         NaN   \n",
       "1                 NaN         NaN                 NaN         NaN   \n",
       "2                 NaN         NaN                 NaN         NaN   \n",
       "3                 NaN         NaN                 NaN         NaN   \n",
       "4                 NaN         NaN                 NaN         NaN   \n",
       "\n",
       "   num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  \n",
       "0                 NaN         NaN                 NaN  \n",
       "1                 NaN         NaN                 NaN  \n",
       "2                 NaN         NaN                 NaN  \n",
       "3                 NaN         NaN                 NaN  \n",
       "4                 NaN         NaN                 NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unique_persons = df[\"userid\"].nunique()\n",
    "\n",
    "print(f\"unique persons: {unique_persons}\")\n",
    "print(f\"number of rows: {df.shape[0]}\")\n",
    "\n",
    "print(f\"Number of unique survey waves: {df['wid'].nunique()}\")\n",
    "\n",
    "earliest_date = df['date'].min()\n",
    "print(f\"earliest_date: {earliest_date}\")\n",
    "\n",
    "latest_date = df['date'].max()\n",
    "print(f\"latest date: {latest_date}\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Before cleaning ==\n",
      "Observations: 165,924\n",
      "Unique individuals: 21,666\n",
      "Survey waves (months): 132\n",
      "Date range: 2014-01 to 2024-12\n",
      "\n",
      "Filled numeracy (from first obs per userid): 936645 cells filled\n",
      "\n",
      "Dropped rows with missing required values: 28,348\n",
      "Dropped outliers for inflation: 119 (kept [-75.000, 100.000])\n",
      "Dropped outliers for house_price_change: 179 (kept [-50.000, 100.000])\n",
      "Dropped outliers for prob_stocks_up: 0 (kept [0.000, 100.000])\n",
      "Total outliers dropped: 298\n",
      "\n",
      "== After cleaning (final dataset) ==\n",
      "Observations: 137,278\n",
      "Unique individuals: 17,701\n",
      "Survey waves (months): 117\n",
      "Date range: 2015-04 to 2024-12\n",
      "\n",
      "Missing values (selected):\n",
      "female                      0\n",
      "age                         0\n",
      "educ                        0\n",
      "inflation                   0\n",
      "house_price_change          0\n",
      "prob_stocks_up              0\n",
      "college                     0\n",
      "num_lit_high                0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Part 2: Data preprocessing ----\n",
    "# Assumes you already have: df = importCSV()\n",
    "\n",
    "# 0) Basic hygiene\n",
    "df = df.copy()\n",
    "if \"date\" in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# --- Helpers for neat reporting ---\n",
    "def sample_stats(_df, title=\"Sample stats\"):\n",
    "    n_obs = len(_df)\n",
    "    n_indiv = _df[\"userid\"].nunique() if \"userid\" in _df.columns else np.nan\n",
    "    n_waves = _df[\"date\"].dt.to_period(\"M\").nunique() if \"date\" in _df.columns else np.nan\n",
    "    dmin = _df[\"date\"].min() if \"date\" in _df.columns else None\n",
    "    dmax = _df[\"date\"].max() if \"date\" in _df.columns else None\n",
    "    print(f\"\\n== {title} ==\")\n",
    "    print(f\"Observations: {n_obs:,}\")\n",
    "    print(f\"Unique individuals: {n_indiv:,}\" if pd.notna(n_indiv) else \"Unique individuals: N/A\")\n",
    "    print(f\"Survey waves (months): {n_waves:,}\" if pd.notna(n_waves) else \"Survey waves (months): N/A\")\n",
    "    if dmin is not None:\n",
    "        print(f\"Date range: {dmin.strftime('%Y-%m')} to {dmax.strftime('%Y-%m')}\")\n",
    "\n",
    "# Snapshot before cleaning\n",
    "sample_stats(df, \"Before cleaning\")\n",
    "\n",
    "# 1) Forward-fill numeracy (per individual) from the first observation\n",
    "#    The term paper says: forward-fill the *_correct variables only (asked at first entry).\n",
    "num_cols = [c for c in df.columns if c.endswith(\"_correct\") and c.startswith(\"num_lit_\")]\n",
    "if num_cols:\n",
    "    first_vals = df.groupby(\"userid\", dropna=False)[num_cols].transform(\"first\")\n",
    "    # Only fill where current is missing\n",
    "    before_missing_num = df[num_cols].isna().sum().sum()\n",
    "    df[num_cols] = df[num_cols].fillna(first_vals)\n",
    "    after_missing_num = df[num_cols].isna().sum().sum()\n",
    "    print(f\"\\nFilled numeracy (from first obs per userid): \"\n",
    "          f\"{before_missing_num - after_missing_num} cells filled\")\n",
    "\n",
    "# 2) Drop rows with missing required fields\n",
    "#    Demographics: female (indicator), age, educ\n",
    "#    Expectations: inflation, house_price_change, prob_stocks_up\n",
    "#    Numeracy: all *_correct columns (after forward fill)\n",
    "required_cols = [\"female\", \"age\", \"educ\", \"inflation\", \"house_price_change\", \"prob_stocks_up\"] + num_cols\n",
    "required_cols = [c for c in required_cols if c in df.columns]  # keep only those that exist\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=required_cols)\n",
    "dropped_missing = before - len(df)\n",
    "print(f\"\\nDropped rows with missing required values: {dropped_missing:,}\")\n",
    "\n",
    "# 3) Drop outliers using 0.1th and 99.9th percentiles for each expectations variable\n",
    "exp_vars = [c for c in [\"inflation\", \"house_price_change\", \"prob_stocks_up\"] if c in df.columns]\n",
    "dropped_outliers_total = 0\n",
    "for col in exp_vars:\n",
    "    q_low = df[col].quantile(0.001)\n",
    "    q_high = df[col].quantile(0.999)\n",
    "    mask_keep = (df[col] >= q_low) & (df[col] <= q_high)\n",
    "    dropped = (~mask_keep).sum()\n",
    "    df = df.loc[mask_keep].copy()\n",
    "    dropped_outliers_total += int(dropped)\n",
    "    print(f\"Dropped outliers for {col}: {int(dropped):,} \"\n",
    "          f\"(kept [{q_low:.3f}, {q_high:.3f}])\")\n",
    "\n",
    "print(f\"Total outliers dropped: {dropped_outliers_total:,}\")\n",
    "\n",
    "# 4) Create 'college' = 1 if educ >= 4 (Bachelor’s or higher), else 0\n",
    "#    (educ is ordinal: 1=no HS/GED, 2=HS/GED, 3=some college/assoc., 4=bachelor’s+)\n",
    "if \"educ\" in df.columns:\n",
    "    df[\"college\"] = (df[\"educ\"] >= 4).astype(int)\n",
    "\n",
    "# 5) Sum correct numeracy answers per row and create 'num_lit_high'\n",
    "if num_cols:\n",
    "    df[\"num_correct\"] = df[num_cols].sum(axis=1)\n",
    "    med = df[\"num_correct\"].median()\n",
    "    # \"more correct responses than the median\"\n",
    "    df[\"num_lit_high\"] = (df[\"num_correct\"] > med).astype(int)\n",
    "\n",
    "# 6) Final sample stats (same structure as Part 1)\n",
    "sample_stats(df, \"After cleaning (final dataset)\")\n",
    "\n",
    "# Optional: quick sanity checks\n",
    "print(\"\\nMissing values (selected):\")\n",
    "for c in [\"female\", \"age\", \"educ\", \"inflation\", \"house_price_change\", \"prob_stocks_up\", \"college\", \"num_lit_high\"]:\n",
    "    if c in df.columns:\n",
    "        print(f\"{c:<22} {df[c].isna().sum():>6}\")\n",
    "\n",
    "# Keep the cleaned DataFrame for later parts\n",
    "df_clean = df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
